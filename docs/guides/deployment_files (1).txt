# ============================================================================
# requirements.txt - Python Dependencies
# ============================================================================
# Save as: requirements.txt
# Install: pip install -r requirements.txt

# Core Framework
asyncio==3.4.3
aiohttp==3.9.1

# LLM Providers
mistralai==0.4.2
google-generativeai==0.3.2
groq==0.4.1
huggingface-hub==0.20.2

# Redis & Caching
redis[hiredis]==5.0.1

# Vector Embeddings
sentence-transformers==2.2.2
numpy==1.24.3

# Utilities
python-dotenv==1.0.0
pydantic==2.5.3

# Monitoring (Optional)
prometheus-client==0.19.0

# ============================================================================
# .env.example - Environment Variables Template
# ============================================================================
# Save as: .env
# Copy this and fill in your actual keys

# LLM Provider API Keys
MISTRAL_API_KEY=your_mistral_key_here
GEMINI_API_KEY=your_gemini_key_here
GROQ_API_KEY=your_groq_key_here
HF_API_KEY=your_huggingface_key_here

# GitHub Integration (Pro Account)
GITHUB_TOKEN=your_github_token_here

# Redis Configuration
REDIS_URL=redis://localhost:6379
REDIS_PASSWORD=
REDIS_DB=0

# MCP Server
MCP_SERVER_URL=http://localhost:3000/mcp

# System Configuration
MAX_REQUESTS_PER_MINUTE=100
CACHE_TTL_SECONDS=3600
MAX_CONVERSATION_HISTORY=50

# Cost Limits (USD)
DAILY_COST_LIMIT=10.00
ALERT_COST_THRESHOLD=5.00

# ============================================================================
# docker-compose.yml - Local Development Setup
# ============================================================================
# Save as: docker-compose.yml
# Run: docker-compose up -d

version: '3.8'

services:
  redis:
    image: redis:7-alpine
    container_name: agent_redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  mcp-server:
    build:
      context: ./mcp-server
      dockerfile: Dockerfile
    container_name: agent_mcp
    ports:
      - "3000:3000"
    environment:
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - PORT=3000
    depends_on:
      - redis
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/health"]
      interval: 10s
      timeout: 5s
      retries: 3

  orchestrator:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: agent_orchestrator
    ports:
      - "8000:8000"
    environment:
      - MISTRAL_API_KEY=${MISTRAL_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - GROQ_API_KEY=${GROQ_API_KEY}
      - HF_API_KEY=${HF_API_KEY}
      - GITHUB_TOKEN=${GITHUB_TOKEN}
      - REDIS_URL=redis://redis:6379
      - MCP_SERVER_URL=http://mcp-server:3000/mcp
    depends_on:
      redis:
        condition: service_healthy
      mcp-server:
        condition: service_healthy
    volumes:
      - ./logs:/app/logs
    restart: unless-stopped

volumes:
  redis_data:

# ============================================================================
# Dockerfile - Main Application Container
# ============================================================================
# Save as: Dockerfile

FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    curl \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# Copy requirements
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application code
COPY agent_platform.py .
COPY api_server.py .

# Expose port
EXPOSE 8000

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1

# Run application
CMD ["python", "api_server.py"]

# ============================================================================
# mcp-server/Dockerfile - MCP Server Container
# ============================================================================
# Save as: mcp-server/Dockerfile

FROM node:18-alpine

WORKDIR /app

# Copy package files
COPY package*.json ./

# Install dependencies
RUN npm ci --only=production

# Copy server code
COPY server.js .

# Expose port
EXPOSE 3000

# Health check
HEALTHCHECK --interval=10s --timeout=5s --retries=3 \
    CMD wget --no-verbose --tries=1 --spider http://localhost:3000/health || exit 1

# Run server
CMD ["node", "server.js"]

# ============================================================================
# mcp-server/package.json - MCP Server Dependencies
# ============================================================================
# Save as: mcp-server/package.json

{
  "name": "agent-mcp-server",
  "version": "1.0.0",
  "description": "MCP server for multi-agent platform",
  "main": "server.js",
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js"
  },
  "dependencies": {
    "express": "^4.18.2",
    "body-parser": "^1.20.2",
    "axios": "^1.6.2",
    "dotenv": "^16.3.1"
  },
  "devDependencies": {
    "nodemon": "^3.0.2"
  }
}

# ============================================================================
# mcp-server/server.js - Complete MCP Server Implementation
# ============================================================================
# Save as: mcp-server/server.js

const express = require('express');
const bodyParser = require('body-parser');
const axios = require('axios');
require('dotenv').config();

const app = express();
app.use(bodyParser.json());

// Health check endpoint
app.get('/health', (req, res) => {
    res.json({ status: 'healthy', timestamp: new Date().toISOString() });
});

// MCP JSON-RPC endpoint
app.post('/mcp', async (req, res) => {
    const { jsonrpc, id, method, params } = req.body;
    
    console.log(`[MCP] Received request: ${params?.name}`);
    
    if (jsonrpc !== '2.0') {
        return res.json({
            jsonrpc: '2.0',
            id,
            error: { code: -32600, message: 'Invalid Request' }
        });
    }
    
    try {
        let result;
        
        switch (params?.name) {
            case 'web_search':
                result = await handleWebSearch(params.arguments);
                break;
            
            case 'github_search_code':
                result = await handleGitHubSearch(params.arguments);
                break;
            
            case 'github_get_file':
                result = await handleGitHubFile(params.arguments);
                break;
            
            case 'brave_search':
                result = await handleBraveSearch(params.arguments);
                break;
            
            default:
                throw new Error(`Unknown tool: ${params?.name}`);
        }
        
        res.json({
            jsonrpc: '2.0',
            id,
            result
        });
        
    } catch (error) {
        console.error(`[MCP] Error:`, error.message);
        res.json({
            jsonrpc: '2.0',
            id,
            error: { code: -32000, message: error.message }
        });
    }
});

// Web Search Handler (DuckDuckGo)
async function handleWebSearch(args) {
    try {
        const response = await axios.get('https://api.duckduckgo.com/', {
            params: {
                q: args.query,
                format: 'json',
                no_html: 1
            },
            timeout: 10000
        });
        
        const data = response.data;
        const results = [];
        
        // Add abstract result if available
        if (data.AbstractText) {
            results.push({
                title: data.Heading || 'Main Result',
                snippet: data.AbstractText,
                url: data.AbstractURL || '',
                source: data.AbstractSource || 'DuckDuckGo'
            });
        }
        
        // Add related topics
        if (data.RelatedTopics && data.RelatedTopics.length > 0) {
            data.RelatedTopics.slice(0, 5).forEach(topic => {
                if (topic.Text) {
                    results.push({
                        title: topic.FirstURL ? topic.FirstURL.split('/').pop() : 'Related',
                        snippet: topic.Text,
                        url: topic.FirstURL || '',
                        source: 'DuckDuckGo Related'
                    });
                }
            });
        }
        
        return {
            query: args.query,
            total_results: results.length,
            results: results
        };
        
    } catch (error) {
        console.error('DuckDuckGo search error:', error.message);
        return {
            query: args.query,
            total_results: 0,
            results: [],
            error: error.message
        };
    }
}

// GitHub Code Search Handler
async function handleGitHubSearch(args) {
    if (!process.env.GITHUB_TOKEN) {
        throw new Error('GITHUB_TOKEN not configured');
    }
    
    const query = `${args.query}${args.language ? ` language:${args.language}` : ''}`;
    
    try {
        const response = await axios.get('https://api.github.com/search/code', {
            params: { 
                q: query,
                per_page: 10
            },
            headers: {
                'Accept': 'application/vnd.github+json',
                'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
                'X-GitHub-Api-Version': '2022-11-28'
            },
            timeout: 15000
        });
        
        return {
            query: args.query,
            total_count: response.data.total_count,
            items: response.data.items.map(item => ({
                name: item.name,
                path: item.path,
                repository: item.repository.full_name,
                url: item.html_url,
                score: item.score
            }))
        };
        
    } catch (error) {
        if (error.response?.status === 403) {
            throw new Error('GitHub API rate limit exceeded');
        }
        throw new Error(`GitHub search failed: ${error.message}`);
    }
}

// GitHub File Content Handler
async function handleGitHubFile(args) {
    if (!process.env.GITHUB_TOKEN) {
        throw new Error('GITHUB_TOKEN not configured');
    }
    
    try {
        const response = await axios.get(
            `https://api.github.com/repos/${args.repo}/contents/${args.path}`,
            {
                headers: {
                    'Accept': 'application/vnd.github+json',
                    'Authorization': `Bearer ${process.env.GITHUB_TOKEN}`,
                    'X-GitHub-Api-Version': '2022-11-28'
                },
                timeout: 15000
            }
        );
        
        const content = Buffer.from(response.data.content, 'base64').toString('utf8');
        
        return {
            repo: args.repo,
            path: args.path,
            size: response.data.size,
            content: content,
            url: response.data.html_url
        };
        
    } catch (error) {
        throw new Error(`GitHub file fetch failed: ${error.message}`);
    }
}

// Brave Search Handler (if API key available)
async function handleBraveSearch(args) {
    if (!process.env.BRAVE_API_KEY) {
        throw new Error('BRAVE_API_KEY not configured');
    }
    
    try {
        const response = await axios.get('https://api.search.brave.com/res/v1/web/search', {
            params: {
                q: args.query,
                count: 10
            },
            headers: {
                'Accept': 'application/json',
                'Accept-Encoding': 'gzip',
                'X-Subscription-Token': process.env.BRAVE_API_KEY
            },
            timeout: 10000
        });
        
        return {
            query: args.query,
            results: response.data.web.results.map(r => ({
                title: r.title,
                snippet: r.description,
                url: r.url
            }))
        };
        
    } catch (error) {
        throw new Error(`Brave search failed: ${error.message}`);
    }
}

// Start server
const PORT = process.env.PORT || 3000;
app.listen(PORT, () => {
    console.log(`✓ MCP Server running on http://localhost:${PORT}`);
    console.log(`✓ Health check: http://localhost:${PORT}/health`);
    console.log(`✓ MCP endpoint: http://localhost:${PORT}/mcp`);
});

# ============================================================================
# api_server.py - FastAPI REST API Wrapper
# ============================================================================
# Save as: api_server.py
# This provides HTTP endpoints for the orchestrator

"""
Production FastAPI server for multi-agent platform
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.responses import StreamingResponse
from pydantic import BaseModel
from typing import Optional, List
import uvicorn
import json

# Import your orchestrator
from agent_platform import ProductionOrchestrator, StreamingOrchestrator

app = FastAPI(
    title="Multi-Agent Platform API",
    description="Production-ready multi-agent orchestration system",
    version="1.0.0"
)

# Global orchestrator instance
orchestrator: Optional[ProductionOrchestrator] = None
streaming_orchestrator: Optional[StreamingOrchestrator] = None

# Request/Response models
class CompletionRequest(BaseModel):
    user_id: str
    prompt: str
    agent_name: Optional[str] = None
    stream: bool = False

class CompletionResponse(BaseModel):
    response: str
    agent: str
    cached: bool
    metadata: dict

@app.on_event("startup")
async def startup_event():
    """Initialize orchestrators on startup"""
    global orchestrator, streaming_orchestrator
    
    orchestrator = ProductionOrchestrator()
    await orchestrator.initialize()
    
    streaming_orchestrator = StreamingOrchestrator()
    await streaming_orchestrator.initialize()
    
    print("✅ API Server ready")

@app.on_event("shutdown")
async def shutdown_event():
    """Cleanup on shutdown"""
    if orchestrator:
        await orchestrator.close()
    if streaming_orchestrator:
        await streaming_orchestrator.close()

@app.get("/health")
async def health_check():
    """Health check endpoint"""
    if not orchestrator:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    status = await orchestrator.get_system_status()
    return status

@app.post("/v1/completions", response_model=CompletionResponse)
async def create_completion(request: CompletionRequest):
    """Standard completion endpoint"""
    if not orchestrator:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    if request.stream:
        raise HTTPException(
            status_code=400, 
            detail="Use /v1/completions/stream for streaming"
        )
    
    try:
        result = await orchestrator.process_request(
            user_id=request.user_id,
            prompt=request.prompt,
            agent_name=request.agent_name
        )
        
        if "error" in result:
            raise HTTPException(status_code=500, detail=result["error"])
        
        return CompletionResponse(**result)
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/completions/stream")
async def create_completion_stream(request: CompletionRequest):
    """Streaming completion endpoint"""
    if not streaming_orchestrator:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    async def event_stream():
        try:
            async for chunk in streaming_orchestrator.stream_request(
                user_id=request.user_id,
                prompt=request.prompt,
                agent_name=request.agent_name
            ):
                yield f"data: {json.dumps(chunk)}\n\n"
        except Exception as e:
            yield f"data: {json.dumps({'type': 'error', 'message': str(e)})}\n\n"
    
    return StreamingResponse(
        event_stream(),
        media_type="text/event-stream"
    )

@app.get("/v1/agents")
async def list_agents():
    """List all available agents"""
    if not orchestrator:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    agents = orchestrator.agents.get_all_agents()
    return {
        "agents": [
            {
                "name": agent.name,
                "description": agent.description,
                "keywords": agent.keywords,
                "cost_tier": agent.cost_tier
            }
            for agent in agents
        ]
    }

@app.get("/v1/stats")
async def get_stats():
    """Get usage statistics"""
    if not orchestrator:
        raise HTTPException(status_code=503, detail="Service not ready")
    
    return orchestrator.llm.get_usage_stats()

if __name__ == "__main__":
    uvicorn.run(
        "api_server:app",
        host="0.0.0.0",
        port=8000,
        reload=False,
        workers=1
    )